## Local LLM ðŸ¤–
A self hosted way of interacting with AI models with a built in RAG pipeline.
